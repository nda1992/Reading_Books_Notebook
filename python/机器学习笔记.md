# 机器学习常用算法

主要记录了一些疑难点.没有很详细的过程.<br>

代码的实现在该目录下的\*.py文件

## 决策树

### 信息熵

某个特征的熵的值越高，表示该类别的分类能力就越强.<br>

类别$x_i$的信息定义为：
$$
l(x_i)=-log_2p(x_i)
$$
$p(x_i)$表示该类别的概率.<br>

将所有类别相加.就得到该特征下的信息熵（即期望值）：
$$
H=-\sum\limits_{i=1}^np(x_i)log_2(p(x_i))
$$
那么使用$H(D)$表示数据集$D$的信息熵.$|D|$表示样本容量.而$k$个类$C_k$，$k=1,2,3,...,k$,$|C_k|$为属于类$C_k​$的样本个数.因此，得到的经验熵公式为：
$$
H(D)=-\sum\limits_{k=1}^k(\frac{|C_k|}{|D|}log_2\frac{|C_k|}{|D|})
$$
例如：某个特征有$15$个数据，只有两个类别，一个类别占$9$个，另一个类别占$6$个，则数据集$D$的信息熵为：
$$
H(D)=-\frac{9}{15}log_2\frac{9}{15}-\frac{6}{15}log_2\frac{6}{15}=0.971
$$












