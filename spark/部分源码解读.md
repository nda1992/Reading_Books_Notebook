# Spark中的部分源码阅读

## Spark的配置

Spark中的配置主要分为内置的配置和用户自定义配置.<br>

spark中的系统配置类为SparkConf.而spark中的每个组件都直接或间接的使用它存储属性，这些属性都存储在如下的数据结构中:

```scala
//key或value的来源都是String类型
private val setting = new ConcurrentHashMap[String,String]()
```

loadDefaults为Boolean类型的构造器属性，将会从系统中加载spark配置:

```scala
if(loadDefaults){
    loadFromSystemProperties(false)
}
private[spark] def loadFromSystemProperties(silent:Boolean):SparkConf={
    for((key,value)<-Utils.getSystemProperties if key.startWith("spark.")){		//获取spark.字符串为前缀的key和value，并调用set方法
        set(key,value,silent)
    }
    this
}
//设置到settings中
private[spark] def set(key:String,value:String,silent:Boolean):SparkConf{
    if(key==null){
        throw new ...
    }
    if(value==null){
        throw new ...
    }
    if(!silent){
        logPrecationWarning(key)
    }
    settings.put(key,value)
    this
}
```

